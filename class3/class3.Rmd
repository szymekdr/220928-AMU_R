---
title: "Class 3"
author: "Szymek Drobniak"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
      code_folding: hide
      toc_depth: 3
  md_document:
      variant: gfm
      toc: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = T)
if(knitr::is_html_output(excludes = c("markdown", "gfm"))) {
  echoing = TRUE
} else {
  echoing = FALSE
}
```

# Zanim zaczniemy

## 0. Przydatne zasoby pomocowe w pracy z `R` - część trzecia

-   [Modele liniowe w ekologii - przegląd](https://www.sciencedirect.com/science/article/abs/pii/S0169534709000196)
-   [Dlaczego nie musimy zagnieżdzać zmiennych?](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.2041-210x.2012.00251.x)
-   [Równoważność metod LM oraz prostych testów statystycznych](https://lindeloev.github.io/tests-as-linear/)
-   [Modele mieszane z `lmer()`](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf)
-   ["Statistical rethinking" - książka o modelach liniowych no. 1](https://bookdown.org/content/4857/)
-   [Linear models in R - wstęp](https://ucdavis-bioinformatics-training.github.io/2019-March-Bioinformatics-Prerequisites/thursday/linear_models.html)
-   [Wszystko co należy wiedzieć o GLMM](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html)


***
```{r class.source = 'fold-show'}
library(tidyverse)
library(MuMIn)
library(lme4)
library(lmerTest)
library(sjPlot)

dane <- read_csv("BTdata.csv", 
                 col_types = cols(sex = col_factor(levels = c("Fem", "Male", "UNK")),
                                  habitat = col_factor(levels = c("forest", "park"))))
dane <- filter(dane, sex != "UNK")
```

# A. Regresja, ANOVA + ANCOVA

## 1. Regresja wielokrotna

We wszystkich modelach liniowych tworzonych w `R` stosujemy konwencję formuły do zapisania zależności między zmiennymi w modelu. Oto kilka podstawowych elementów formuły, wraz z ich interpretacją:

Formuła|Znaczenie
-------|---------
`y ~ x`|Regresja prosta (`x` ciągłe) lub jednokierunkowa ANOVA (`x` kategoryczne); jeśli `x` ma 2 poziomy taka notacja da wynik identyczny z `t.test()`
`y ~ x + z`|Regresja wielokrotna (`x` i `z` ciągłe); dwukierunkowa ANOVA (`x` i `z` kategoryczne); ANCOVA (jedna zmienna ciągła, druga kategoryczna)
`y ~ x * z`|Model liniowy z interakcją `x`$\times$`y`
`y ~ x + z + x:z`|Alternatywny zapis poprzedniego modelu
`y ~ (x + z + a)^2`|Model z 3 czynnikami, i ich wszystkimi interakcjami 2 stopnia (zapis równoważny `x + z + a + x:a + x:z + z:a`)
`y ~ x * z * a`|Model z 3 czynnikami i ich wszystkimi interakcjami (łącznie z `x:z:a`)
`y ~ x/z`|Model ze zmienną `z` zagnieżdżoną w `x`
`y ~ x + (1|z)`|Model z efektem losowym `z` (notacja `lmer()` oraz `lme()`)

**Zadanie** Opierając się na prostej regresji skonstruuj model, w którym na `tarsus` potencjalnie wpływają: `hatchdate`, `sex`, `habitat`, interakcja `habitat`$\times$`hatchdate`, interakcja `sex`$\times$`hatchdate`. Zapisz go w nowym obiekcie - czy którykolwiek czynnik modelu jest istotny statystycznie?

**Oczekiwany wynik**
```{r echo = echoing}
model1 <- lm(tarsus ~ hatchdate + habitat + sex + habitat:hatchdate + hatchdate:sex,
             data = dane)
summary(model1)
plot(model1)
```

Uprość model usuwając kolejno nieistotne interakcje. Jaka jest ostateczna interpretacja finalnego modelu?

**Oczekiwany wynik**
```{r echo = echoing}
model1 <- lm(tarsus ~ hatchdate + habitat + sex + habitat:hatchdate,
             data = dane)
summary(model1)

model1 <- lm(tarsus ~ hatchdate + habitat + sex,
             data = dane)
summary(model1)
```

$\blacksquare$

## 2. Regresja wielokrotna *via* seleckja modeli

Aby przeprowadzić selekcję modeli musimy najpierw ponownie policzyć najbardziej złożony model - tzw. model maksymalny.

```{r class.source = 'fold-show'}
model0 <- lm(tarsus ~ hatchdate + habitat + sex + habitat:hatchdate + hatchdate:sex,
             data = dane, na.action = 'na.fail')
```

Funkcja `dredge()` w pakiecie `MuMIn` przeprowadza automatyczną selekcję modeli, wraz z dopasowaniem modeli zagnieżdżonych w głównym modelu stworzonym powyżej.

**Zadanie** Spróbuj wykonać taką selekcję, zapisując jej wynik do obiektu `model_sel`. Następnie zobacz jak wygląda powstały w ten sposób obiekt.

**Oczekiwany wynik**
```{r echo = echoing}
model_sel <- dredge(model0, trace = T)
model_sel
```

Jak zinterpretujesz powstałe rezultaty? Który model jest najlepszy? Czy jest to wiodące prowadzenie na tle innych modeli?

**Zadanie** Użyj funkcji `model_avg()` by przeprowadzić uśrednianie modeli mieszczących się w zakresie deltaAICc <= 2 (`subset = delta <= 2`). Czy wyniki są bardziej jednoznaczne?

**Oczekiwany wynik**
```{r echo = echoing}
model_average <- model.avg(model_sel, subset = delta <= 2)
summary(model_average)
```

$\blacksquare$

## 3. ANOVA

Zaimportuj do `R` dane `pg.csv`.

**Zadanie** Korzystając z funkcji `lm()` skonstruuj model, w którym zmienną zależną jest `weight` a niezależnymi `group` oraz `mod`. Jak wyglądają wyniki takiego modelu?

**Oczekiwany wynik**
```{r echo = echoing}
model3 <- lm(weight ~ group + mod, data = plantgr)
summary(model3)
```

**Zadanie** Poarównaj uzyskany output z wynikiem użycia w podobny sposób funkcji `aov()`.

**Oczekiwany wynik**
```{r echo = echoing}
model4 <- aov(weight ~ group + mod, data = plantgr)
summary(model4)
```

Czy dodanie do modelu interakcji `group:mod` wyjaśnia dodatkową zmienność modelu? **Wskazówka** $R^2$ modelu policzonego za pomocą funkcji `aov()` można podejrzeć stosując `summary.lm(model)$r.squared`.

**Oczekiwany wynik**
```{r echo = echoing}
model5 <- aov(weight ~ group * mod, data = plantgr)
summary(model5)

summary.lm(model4)$r.squared
summary.lm(model5)$r.squared
```

**Zadanie** Czy model z interakcją spełnia założenia modelu liniowego?

**Oczekiwany wynik**
```{r echo = echoing}
plot(model5)
```

$\blacksquare$

# B. Model uogólniony

## 1. Regresja logistyczna - GLM

Zaimportuj dane `BTEPC.txt` do obiektu `btepc`. Zmienne `MAGEO` i `FAGEO` powinny mieć charakter kategoryczny (`factor`). Jakiego rodzaju zmienne znajdują się w pliku?

**Zadanie** Skonstruuj wykres pokazujący zależność `FEPC` od `MTAR`.

**Oczekiwany wynik**
```{r echo = echoing}
plot(jitter(FEPC, 0.3) ~ MTAR, data = btepc)
```

**Zadanie** Skonstruuj model testujący wpływ interakcji długości skoku partnera socjalnego (`MTAR`) i wieku samicy (`FAGEO`) na prawdopodobieństwo "skoku-w-bok" u sikory modrej. Pamiętaj o zmianie rodziny rozkładów dla modelu GLM.

**Spodziewany wynik**
```{r echo = echoing}
model6 <- glm(FEPC ~ MTAR*FAGEO, data = btepc, family = "binomial")
summary(model6)
```

Poniższy kod pozwala zobaczyć przewidywania modelu na realnej, biologicznej skali prawdopodobieństwa.
```{r class.source = 'fold-show'}
plot_model(model6, type = "int")
```

$\blacksquare$

# C. Model mieszany

## 1. Czy skok jest odziedziczalny?

Aby przetestować genetyczną komponentę cechy zmierzonej w ramach eksperymentu genetycznego wykorzystującego *cross-fostering* należy zbadań model zawierający efekty losowe gniazda wychowywania i gniazda genetycznego (rodziny, matki genetycznej). Czynniki takie typowo analizujemy jako efekty losowe - model musi więc mieć charakter mieszany.

Załaduj dane `BTdata.csv`, zadbaj by `fosternest` oraz `dam` miały charakter czynników kategorycznych (`factor`).

```{r class.source = 'fold-show'}
dane$fosternest <- as.factor(dane$fosternest)
dane$dam <- as.factor(dane$dam)
```

Model dopasujemy w funkcji `lmer()` z pakietu `lme4` - zawierać ona będzie czynnik ustalony płci oraz czynniki losowe `fosternest` i `dam`. 

**Zadanie** Wiedząc, że w `lmer()` czynnik losowy dodajemy wg konwencji `(1|nazwa_czynnika)` - skonstruuj i policz odpowiedni model. Gdzie w jego podsumowaniu znajdują się informacje o efektach losowych? Czy model spełnia założenia modelu liniowego?

**Spodziewany wynik**
```{r echo = echoing}
model7 <- lmer(tarsus ~ sex + (1|fosternest) + (1|dam), data = dane)
plot(model7)
summary(model7)
```

**Zadanie** Aby przetestować czy czynnik losowy jest istotny statystycznie oblicz konkurencyjny model pozbawiony czynnika rodzica genetycznego (`dam`) i porównaj go z wcześniejszym modelem za pomocą funkcji `anova()`. Który model ma niższe *AIC* i jest tym samym lepszy? Czy różnica jest istotna statystycznie?

**Spodziewany wynik**
```{r echo = echoing}
model8 <- lmer(tarsus ~ sex + (1|fosternest), data = dane)
anova(model7, model8)
```

$\blacksquare$

## 2. Czy temperatura różnie wpływ na tempo wzrostu u różnych gatunków plnaktonu?

Załaduj dane `PLD.txt` do obiektu `pld`. Przyjrzyj się strukturze danych. Zamień kolumnę `species` na `factor`:

```{r class.source = 'fold-show'}
pld$species <- as.factor(pld$species)
```

**Zadanie** Stwórz model mieszany analizujący zależność długości okresu larwalnego (PLD) od temperatury u różnych gatunków bezkręgowców. Użyj `species` jako efektu losowego, zlogarytmuj w modelu zmienną zależną i niezależną. Czy zmienność między gatunkami jest duża, czy mała?

**Spodziewany wynik**
```{r echo = echoing}
model9 <- lmer(log(pld) ~ log(temp) + (1|species), data = pld)
summary(model9)
```


**Zadanie** Uzupełnij model możliwością zmiennych międzygatunkowo nachyleń zależności `pld~temp` zamieniając `1` w definicji efektu losowego na `1+log(temp)`. Który model jest lepszy?

```{r echo = echoing}
model10 <- lmer(log(pld) ~ log(temp) + (1+log(temp)|species), data = pld)
summary(model10)
anova(model9, model10)
```

Poniższa funkcja (szczegółami zajmiemy się jutro) ilustruje badane dane, pokazując zależności `log(pld)~log(temp)` dla wszystkich obecnych w danych gatunków:

```{r class.source = 'fold-show'}
library(ggplot2)
qplot(x = log(temp), y = log(pld),
      data = pld, col = species, ) +
  geom_smooth(method = "lm", se = F) +
  theme_bw() + theme(legend.position="none")
```

$\blacksquare$

# D. Expressem przez *bootstrapping*

Do tej pory do naszych analiz wykorzystywaliśmy metody parametryczne - możemy jednak spróbować wykorzystać inną, prostszą metodę, która pozwoli nam uwolnić się od ograniczeń rozkładowych naszych danych. Spójrzmy na przykład na rozkład zmiennej `hatchdate` - nie jest on najpiękniejszy i na pierwszy rzut oka nie przypomina on zgrabnego rozkładu normalnego:

```{r class.source = 'fold-show'}
hist(dane$hatchdate, 15)
```

Spróbujmy skonstruować test oparty na bootstrappingu, którym sprawdzimy czy ptaki z lasu (`forest`) różnią się pod kątem daty klucia od ptaków z parków (`park`). Szybki rzut oka na wykres pudełkowy nie wskazuje na zbyt wielkie różnice.

```{r class.source = 'fold-show'}
plot(hatchdate ~ habitat, data = dane)
```

1. Do skonstruowania bootstrappingu wykorzystamy pętlę `for`, która pozwala powtarzać jakąś operację wiele razy. Jeśli chcielibyśmy np. wydrukować na ekranie (`print()`) jakiś tekst pięć razy - moglibyśmy osiągnąć to w następujący sposób:

```{r class.source = 'fold-show'}
for(i in 1:5) {
  print("Tekst najbardziej oryginalny!")
}
```

Zauważ, że pętla for wykorzystuje jakąś zmienną (tutaj `i`), zmieniając jej wartość w zadanym zakresie (tutaj `1:5`) i za każdym razem (dla każ∂ego `i`) wykonując jakieś działania ujęte wewnątrz `{}`.

2. Potrzebna nam będzie również metoda losowego wybierania pewnych wierszy z naszych oryginalnych danych - ze zwracaniem. Idealnie do tego nadaje się funkcja `sample()`. Zobaczmy, jak losuje ona zadaną liczbę wartości (10) z podanej listy (liczby 1 do 20), ze zwracaniem (`replace = T`):

```{r class.source = 'fold-show'}
sample(1:20, size = 10, replace = T)
```

**Uwaga!** Funkcja ta używa generatora liczb pseudolosowych - więc u każdego wynik tej operacji będzie inny!

3. Wreszcie - musimy mieć naszą statystykę testową. Niech będzie nią różnica między średnią datą klucia w sikor leśnych i parkowych $d_0$ - jeśli wynosi ona zero, ptaki mają identyczne daty klucia:

```{r class.source = 'fold-show'}
d0 <- mean(filter(dane, habitat == "forest")$hatchdate) -
  mean(filter(dane, habitat == "park")$hatchdate)
d0
```

Ujemna różnica wskazuje na nieco wyższą wartość (późniejsze klucie) w parku - pytanie, czy istotnie późniejsze?

Oto co powinna robić nasza procedura bootstrappingu:

* Krok 1: wylosuj z zestawu danych k = `r nrow(dane)` obserwacji (wierszy) ze zwracaniem (tyle wierszy składa się na oryginalny zestaw danych).
* Krok 2: dla każdego z tych wylosowanych zestawów policz jego własną statystykę `d` - różnicę w średniej dacie klucia między lasem i parkiem.
* Krok 3: Powtórz całą procedurę N = 1000 razy (jest to arbitralna wielkość, im więcej - tym lepiej). Za każdym razem zapisz wynik do zbiorczego obiekty `out`.
* Krok 4: Skonstruuj rozkład statystyki `d` i zobacz gdzie wypada w niej jej oryginalna (oparta na wejściowych danych) wartość `d0`.

```{r class.source = 'fold-show'}
N <- 1000 # liczba zakładanych powtórzeń
k <- nrow(dane) # wielkość oryginalnego zbioru danych

# oryginalna statystyka testowa
d0 <- mean(filter(dane, habitat == "forest")$hatchdate) -
  mean(filter(dane, habitat == "park")$hatchdate)

# obiekt wynikowy przygotowany na N=1000 końcowych wartości
out <- numeric(N)

for(i in 1:N) {
  
  # losujemy 828 wierszy, ze zwracaniem
  # a oryginalnej puli unikatowych 828 wierszy danych
  rows <- sample(1:k, size = k, replace = T)
  
  # tworzymy tymczasowe dane wewnątrz pętli
  # zawierające tylko wylosowane wiersze
  temp_dane <- dane[rows, ]
  
  # oblicza na podstawie tak przygotowanych danych
  # tymczasową statystykę testową dla powtórzenia
  # nr i pętli
  d_temp <- mean(filter(temp_dane, habitat == "forest")$hatchdate) -
    mean(filter(temp_dane, habitat == "park")$hatchdate)
  
  # zapisujemy wyliczoną statystykę
  # do zmiennej out w miejscu i
  out[i] <- d_temp
  
}
```

Wyświetlmy rozkład symulowanej statystyki `d` oraz położenie `d0` na rozkładzie:

```{r class.source = 'fold-show'}
hist(out, 50)
abline(v = d0, lwd = 2)
abline(v = 0, col = "red", lwd = 2, lty = 2)
```

Jak podejdziesz to odpowiedzi na pytanie - czy ta symulacja wskazuje na istotną statystycznie różnicę między symulowaną statystyką a wartością zero?

$\blacksquare$